{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T09:23:27.212161Z",
     "start_time": "2025-04-17T09:22:08.958137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "import arxiv\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import PyPDF2\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import openai\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pytrends.request import TrendReq\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# LLM Configuration\n",
    "def get_llm_config():\n",
    "    return {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "\n",
    "# Create Assistant Agent\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"research_assistant\",\n",
    "    system_message=\"\"\"\n",
    "    You are an AI assistant specialized in research tasks, including paper recommendations, summarization, trend analysis, idea generation, and evaluate idea feasibility.\n",
    "    All responses must adhere to the following guidelines:\n",
    "\n",
    "    1) Do not fabricate information in the absence of sufficient evidence, and clearly indicate \"알 수 없습니다\" or \"잘 모르겠습니다\" if uncertain.\n",
    "    2) Verify possible information step-by-step before responding, marking ambiguous or unclear sources as \"확실하지 않음.\"\n",
    "    3) Base final responses only on verified information, keeping answers concise. If speculation is necessary, disclose it by stating \"추측입니다.\"\n",
    "    4) If the user's query is unclear or requires further information, first request additional context or details from the user.\n",
    "    5) Do not confidently assert unverified facts and provide evidence if necessary, including sources or references when available.\n",
    "    6) For every answer, specify supporting information with references or summarized related links and materials wherever possible.\n",
    "\n",
    "    # Steps\n",
    "    - **Paper Recommendations:**\n",
    "      1. Identify the specific field or topic area the user is interested in.\n",
    "      2. Search for recent and relevant papers within that field.\n",
    "      3. Filter and rank them based on relevance, publication date, and impact factor.\n",
    "      4. Provide a list of recommended papers with a brief description of each.\n",
    "\n",
    "    - **Summarization:**\n",
    "      1. Extract key points and findings from the provided paper or research material.\n",
    "      2. Highlight significant contributions and conclusions.\n",
    "      3. Write a concise summary that communicates the main insights.\n",
    "\n",
    "    - **Trend Analysis:**\n",
    "      1. Gather data or publications related to a specific research domain over time.\n",
    "      2. Identify patterns, common themes, emerging topics, and shifts in focus.\n",
    "      3. Present an analysis that explains these trends.\n",
    "\n",
    "    - **Idea Generation:**\n",
    "     1. Understand the user's area of interest and goals.\n",
    "     2. Brainstorm and gather inspiration from recent publications, trends, and gaps in the literature.\n",
    "     3. Present new research ideas or questions that can be pursued further.\n",
    "\n",
    "    # Output Format\n",
    "\n",
    "    - Responses should be in paragraph form, clearly structured and organized according to the task type.\n",
    "    - For lists, use bullet points or numbered lists where appropriate.\n",
    "    - Ensure any visualizations are described in detail with clear explanations for what they represent.\n",
    "    - Use a formal and informative tone suitable for academic or professional contexts.\n",
    "\n",
    "    # Notes\n",
    "\n",
    "    - Ensure recommendations are current and papers are from credible sources.\n",
    "    - For trend analysis, consider incorporating historical data and future predictions when possible.\n",
    "    - When generating ideas, ensure they are feasible and backed by current research to a reasonable extent.\"\"\",\n",
    "    llm_config=get_llm_config()\n",
    ")\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Create User Proxy Agent\n",
    "def create_user_proxy():\n",
    "    return UserProxyAgent(\n",
    "        name=\"Admin\",\n",
    "        system_message=\"You are the user proxy handling requests and interacting with the AI assistant.\",\n",
    "        human_input_mode=\"ALWAYS\",\n",
    "        default_auto_reply=\"Reply 'TERMINATE' if the task is done.\",\n",
    "        code_execution_config={\"use_docker\": False}\n",
    "    )\n",
    "\n",
    "# Task functions\n",
    "def recommend_papers_tool(query: str, year: int = None, limit: int = 5) -> str:\n",
    "    try:\n",
    "        search_query = f\"{query}\"\n",
    "        if year:\n",
    "            search_query += f\" AND submittedDate:[{year}0101 TO {year}1231]\"\n",
    "\n",
    "        user = arxiv.Client()\n",
    "        search = arxiv.Search(query=search_query, max_results=limit, sort_by=arxiv.SortCriterion.Relevance)\n",
    "        papers = [\n",
    "            f\"Title: {result.title}\\nAuthors: {', '.join([author.name for author in result.authors])}\\nAbstract: {result.summary}\\nSubmitted Date: {result.updated.date().isoformat()}\\n\"\n",
    "            for result in user.results(search)\n",
    "        ]\n",
    "        return f\"Recommended papers for '{query}':\\n\\n\" + \"\\n\\n\".join(papers)\n",
    "    except Exception as e:\n",
    "\n",
    "        return f\"Error while recommending papers: {e}\"\n",
    "\n",
    "def summarize_pdf_tool(url: str) -> str:\n",
    "    try:\n",
    "        nltk.download('punkt_tab')\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        memory_file = BytesIO(response.content)\n",
    "        pdf_reader = PyPDF2.PdfReader(memory_file)\n",
    "        pdf_text = \"\".join(page.extract_text() for page in pdf_reader.pages)\n",
    "\n",
    "        if not pdf_text.strip():\n",
    "            return \"No text could be extracted from the PDF.\"\n",
    "\n",
    "        parser = PlaintextParser.from_string(pdf_text, Tokenizer(\"english\"))\n",
    "        summarizer = LexRankSummarizer()\n",
    "        total_sentences = len(parser.document.sentences)  # 전체 문장 개수 계산\n",
    "        summary_length = max(3, total_sentences // 5)  # 전체 문장의 20%를 요약 (최소 3문장)\n",
    "\n",
    "        summary = summarizer(parser.document, sentences_count=summary_length)\n",
    "        return \"PDF Summary: \" + \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error summarizing PDF: {e}\"\n",
    "\n",
    "# 연구 트렌드 분석 툴\n",
    "\n",
    "def extract_research_trends(query: str, year: int = 2025, limit: int = 10) -> str:\n",
    "    papers = recommend_papers_tool(query, year, limit)\n",
    "    abstracts = [p.split(\"\\n\")[3] for p in papers.split(\"\\n\\n\") if \"Abstract:\" in p]\n",
    "\n",
    "    if not abstracts:\n",
    "        return \"No abstracts found. Unable to analyze trends.\"\n",
    "\n",
    "    # TF-IDF 적용\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=10)\n",
    "    tfidf_matrix = vectorizer.fit_transform(abstracts)\n",
    "    top_keywords = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # LLM을 활용해 트렌드 요약\n",
    "    prompt = f\"\"\"\n",
    "    최근 {query} 관련 연구에서 도출된 주요 키워드는 {', '.join(top_keywords)}입니다.\n",
    "    이 키워드를 기반으로 최근 연구 트렌드를 분석해 주세요.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 연구 아이디어 생성 툴\n",
    "def generate_research_idea(query: str, year: int = 2025, limit: int = 20) -> str:\n",
    "    papers = recommend_papers_tool(query, year, limit)\n",
    "    abstracts = [p.split(\"\\n\")[3] for p in papers.split(\"\\n\\n\") if \"Abstract:\" in p]\n",
    "\n",
    "    if not abstracts:\n",
    "        return \"No abstracts found. Unable to generate research ideas.\"\n",
    "\n",
    "    # 연구 공백(한계점) 분석 → 새로운 연구 아이디어 도출\n",
    "    prompt = f\"\"\"\n",
    "    최근 {query} 관련 연구 논문을 참고하세요:\n",
    "    {abstracts[:3]}\n",
    "\n",
    "    1) 이 논문들에서 제시된 주요 연구 한계점(Gap)은 무엇인가요?\n",
    "    2) 이를 해결할 수 있는 새로운 연구 아이디어를 제안하세요.\n",
    "    3) 실현 가능성을 1~10점으로 평가하고, 이유를 설명하세요.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# 연구 아이디어 실현 가능성 평가 툴\n",
    "def evaluate_feasibility(research_idea: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Here is a research idea:\n",
    "    {research_idea}\n",
    "\n",
    "    다음 기준을 적용하여 실현 가능성을 평가하세요:\n",
    "    1) 기술 준비 수준(TRL) → 1~9단계\n",
    "    2) 데이터 가용성 (1: 매우 부족 ~ 10: 풍부)\n",
    "    3) 연구 수행 난이도 (1: 쉬움 ~ 10: 어려움)\n",
    "\n",
    "    각 항목별 점수를 부여하고, 총평을 작성하세요.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Register tools to the assistant\n",
    "assistant_agent.register_for_llm(name=\"recommend_papers\", description=\"Recommend research papers.\")(recommend_papers_tool)\n",
    "assistant_agent.register_for_llm(name=\"summarize_pdf\", description=\"Summarize plain text.\")(summarize_pdf_tool)\n",
    "assistant_agent.register_for_llm(name=\"extract_research_trends\", description=\"Analyze research trends from recent papers.\")(extract_research_trends)\n",
    "assistant_agent.register_for_llm(name=\"generate_research_idea\", description=\"Generate novel research ideas.\")(generate_research_idea)\n",
    "assistant_agent.register_for_llm(name=\"evaluate_feasibility\", description=\"Evaluate the feasibility of a research idea.\")(evaluate_feasibility)\n",
    "\n",
    "# Initialize User Proxy\n",
    "user_proxy = create_user_proxy()\n",
    "user_proxy.register_for_execution(name=\"recommend_papers\")(recommend_papers_tool)\n",
    "user_proxy.register_for_execution(name=\"summarize_pdf\")(summarize_pdf_tool)\n",
    "user_proxy.register_for_execution(name=\"extract_research_trends\")(extract_research_trends)\n",
    "user_proxy.register_for_execution(name=\"generate_research_idea\")(generate_research_idea)\n",
    "user_proxy.register_for_execution(name=\"evaluate_feasibility\")(evaluate_feasibility)\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to the interactive research assistant!\")\n",
    "    print(\"You can ask questions like:\")\n",
    "    print(\"- 추천: LLM에 관한 논문 3개 추천해줘, 2023년 이후.\")\n",
    "    print(\"- 요약: 연구 논문의 내용을 요약해줘.\")\n",
    "    print(\"- 연구 트렌드 분석: 특정 주제의 최신 연구 동향을 분석해줘.\")\n",
    "    print(\"- 연구 아이디어 생성: 새로운 연구 주제를 추천해줘.\")\n",
    "    print(\"- 연구 아이디어 실현 가능성 평가: 연구 아이디어의 현실성을 평가해줘.\")\n",
    "    # 종료 방법 안내 추가\n",
    "    print(\"\\nType 'exit' or 'quit' at the 'You: ' prompt below to end the session.\") \n",
    "\n",
    "\n",
    "    while True:\n",
    "        # 이 프롬프트는 각 작업 요청 전에 표시됩니다.\n",
    "        user_input = input(\"You: \").strip() \n",
    "        \n",
    "        # 여기서 'exit' 또는 'quit'를 입력하면 프로그램이 종료됩니다.\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Exiting the assistant. Goodbye!\")\n",
    "            break # while 루프를 탈출합니다.\n",
    "\n",
    "        try:\n",
    "\n",
    "            response = user_proxy.initiate_chat(\n",
    "                assistant_agent, \n",
    "                messages=[{\"role\": \"user\", \"content\": user_input}]\n",
    "            )\n",
    "            print(f\"Assistant: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the interactive research assistant!\n",
      "You can ask questions like:\n",
      "- 추천: LLM에 관한 논문 3개 추천해줘, 2023년 이후.\n",
      "- 요약: 연구 논문의 내용을 요약해줘.\n",
      "- 연구 트렌드 분석: 특정 주제의 최신 연구 동향을 분석해줘.\n",
      "- 연구 아이디어 생성: 새로운 연구 주제를 추천해줘.\n",
      "- 연구 아이디어 실현 가능성 평가: 연구 아이디어의 현실성을 평가해줘.\n",
      "\n",
      "Type 'exit' or 'quit' at the 'You: ' prompt below to end the session.\n",
      "\u001B[33mAdmin\u001B[0m (to research_assistant):\n",
      "\n",
      "123\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mresearch_assistant\u001B[0m (to Admin):\n",
      "\n",
      "안녕하세요! 도움이 필요한 부분이 있으시면 구체적으로 말씀해 주세요. 연구 관련 도움이 필요하시면 어떤 주제나 분야에 대해 더 알고 싶으신지 알려주시면 좋겠습니다.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mAdmin\u001B[0m (to research_assistant):\n",
      "\n",
      "123\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mresearch_assistant\u001B[0m (to Admin):\n",
      "\n",
      "안녕하세요! 어떤 도움이 필요하신지 구체적으로 알려주시면 도움을 드리겠습니다. 연구 관련 질문이나 다른 문의 사항이 있으면 말씀해 주세요.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001B[0m\n",
      "\u001B[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001B[0m\n",
      "\u001B[33mAdmin\u001B[0m (to research_assistant):\n",
      "\n",
      "Reply 'TERMINATE' if the task is done.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mresearch_assistant\u001B[0m (to Admin):\n",
      "\n",
      "If you have no further questions or requests, please reply with 'TERMINATE' to end the task. If you need more assistance, feel free to ask!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mAdmin\u001B[0m (to research_assistant):\n",
      "\n",
      "quit\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mresearch_assistant\u001B[0m (to Admin):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant: ChatResult(chat_id=None, chat_history=[{'content': '123', 'role': 'assistant', 'name': 'Admin'}, {'content': '안녕하세요! 도움이 필요한 부분이 있으시면 구체적으로 말씀해 주세요. 연구 관련 도움이 필요하시면 어떤 주제나 분야에 대해 더 알고 싶으신지 알려주시면 좋겠습니다.', 'role': 'user', 'name': 'research_assistant'}, {'content': '123', 'role': 'assistant', 'name': 'Admin'}, {'content': '안녕하세요! 어떤 도움이 필요하신지 구체적으로 알려주시면 도움을 드리겠습니다. 연구 관련 질문이나 다른 문의 사항이 있으면 말씀해 주세요.', 'role': 'user', 'name': 'research_assistant'}, {'content': \"Reply 'TERMINATE' if the task is done.\", 'role': 'assistant', 'name': 'Admin'}, {'content': \"If you have no further questions or requests, please reply with 'TERMINATE' to end the task. If you need more assistance, feel free to ask!\", 'role': 'user', 'name': 'research_assistant'}, {'content': 'quit', 'role': 'assistant', 'name': 'Admin'}, {'content': 'TERMINATE', 'role': 'user', 'name': 'research_assistant'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0.044520000000000004, 'gpt-4-turbo-2024-04-09': {'cost': 0.044520000000000004, 'prompt_tokens': 3840, 'completion_tokens': 204, 'total_tokens': 4044}}, 'usage_excluding_cached_inference': {'total_cost': 0.03363000000000001, 'gpt-4-turbo-2024-04-09': {'cost': 0.03363000000000001, 'prompt_tokens': 3018, 'completion_tokens': 115, 'total_tokens': 3133}}}, human_input=['123', '123', '', 'quit', 'exit'])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 243\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mType \u001B[39m\u001B[33m'\u001B[39m\u001B[33mexit\u001B[39m\u001B[33m'\u001B[39m\u001B[33m or \u001B[39m\u001B[33m'\u001B[39m\u001B[33mquit\u001B[39m\u001B[33m'\u001B[39m\u001B[33m at the \u001B[39m\u001B[33m'\u001B[39m\u001B[33mYou: \u001B[39m\u001B[33m'\u001B[39m\u001B[33m prompt below to end the session.\u001B[39m\u001B[33m\"\u001B[39m) \n\u001B[32m    241\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m    242\u001B[39m     \u001B[38;5;66;03m# 이 프롬프트는 각 작업 요청 전에 표시됩니다.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m243\u001B[39m     user_input = \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mYou: \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m.strip() \n\u001B[32m    245\u001B[39m     \u001B[38;5;66;03m# 여기서 'exit' 또는 'quit'를 입력하면 프로그램이 종료됩니다.\u001B[39;00m\n\u001B[32m    246\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m user_input.lower() \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m\"\u001B[39m\u001B[33mexit\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mquit\u001B[39m\u001B[33m\"\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/AIRAS/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001B[39m, in \u001B[36mKernel.raw_input\u001B[39m\u001B[34m(self, prompt)\u001B[39m\n\u001B[32m   1280\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1281\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[32m-> \u001B[39m\u001B[32m1282\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1283\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1284\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1285\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1286\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1287\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/AIRAS/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001B[39m, in \u001B[36mKernel._input_request\u001B[39m\u001B[34m(self, prompt, ident, parent, password)\u001B[39m\n\u001B[32m   1322\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1323\u001B[39m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[32m   1324\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mInterrupted by user\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1325\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1326\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1327\u001B[39m     \u001B[38;5;28mself\u001B[39m.log.warning(\u001B[33m\"\u001B[39m\u001B[33mInvalid Message:\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
